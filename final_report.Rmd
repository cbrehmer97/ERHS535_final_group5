---
title: "Final Report"
author: "Nikki Johnson, Molly Hischke, Collin Brehmer, and Kyle Hancock"
date: "12/9/2019"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, message = FALSE)
```

# Introduction: Research question, and Why did you decide to ask this question?

The Daily Double is an important part of the game of Jeopardy. If a player can effectively predict where the Daily Doubles will be on the board they have a clear advantage to win the game. Recent Jeopardy contestant, James Holzhauer, became known for his strategy of hopping around the board to find the Daily Doubles and then betting larger than normal quantities. In just 32 games, his total winnings reached almost $2.5 million (an average of over $75,000 per game).

What positions on the Jeopardy board are most likely to be a Daily Double? Several people have attempted to answer this question recently and their results can be found in a variety of different sources. Finding the answer to this question is not as simple as it seems at first. The common datasets for Jeopardy questions do not contain the questions that were not asked. This can make finding the exact x and y positions difficult. Multiple approaches can be taken to deal with this issue. The approach taken to develop the figures in this report are described in the methods section. The answer to this question can be effectively presented visually through a heatmap that shows each position on the Jeopardy board. This important question presents a challenge in data cleaning, but when done correctly can result in interesting figures that has drawn the attention of many Jeopardy fans and data enthusiasts.

# Methods: 

How did you investigate the data to try to answer your question? This should not include R code (save that for the tutorial part), but rather should use language like “To determine if … was associated with …, we measured the correlation …”. It’s fine for this project if the Methods are fairly simple (“We investigated the distribution of … using boxplots …”, “We took the mean and interquartile range of …”, “We mapped state-level averages of …”, etc.). Why do you choose to use the Methods you used? Why do you think they’re appropriate and useful for your project?
```{r, echo = FALSE}
library(tidyverse)
library(ggplot2)
jeopardy_board <- tibble(
  x_pos = c("Category 1", "Category 1", "Category 1", 
            "Category 1", "Category 1", 
            "Category 2", "Category 2", "Category 2", 
            "Category 2", "Category 2",
            "Category 3", "Category 3", "Category 3", 
            "Category 3", "Category 3", 
            "Category 4", "Category 4", "Category 4", 
            "Category 4", "Category 4", 
            "Category 5", "Category 5", "Category 5", 
            "Category 5", "Category 5",
            "Category 6", "Category 6", "Category 6", 
            "Category 6", "Category 6"),
  y_pos = c(200, 400, 600, 800, 1000, 
            200, 400, 600, 800, 1000,
            200, 400, 600, 800, 1000,
            200, 400, 600, 800, 1000,
            200, 400, 600, 800, 1000, 
            200, 400, 600, 800, 1000))

jeopardy_board <- jeopardy_board %>% 
  mutate(number_of_dd = c(1, 0, 0, 2, 1,
                          1, 0, 1, 1, 1,
                          1, 1, 1, 1, 1,
                          1, 1, 1, 0, 1,
                          1, 0, 0, 1, 1,
                          1, 1, 1, 0, 1),
          text = c(NA, "MISSING", "MISSING", "Daily Double", NA,
                          NA, "MISSING", NA, NA, NA,
                          NA, NA, NA, NA, NA,
                          NA, NA, NA, "MISSING", NA,
                          NA, "MISSING", "MISSING", NA, NA,
                          NA, NA, NA, "MISSING", NA)) 
weighted_jeopardy_board <- jeopardy_board %>% 
  mutate(number_of_dd = c(NA, 0.33, 0.33, 0.33, NA,
                          NA, NA, NA, NA, NA,
                          NA, NA, NA, NA, NA,
                          NA, NA, NA, NA, NA,
                          NA, NA, NA, NA, NA,
                          NA, NA, NA, NA, NA)) 

```

The Jeopardy dataset utilized was found on GitHub which included the air date, round, daily double information, category, value, question, answer, comments, and notes. The dataset was filtered to only include dates beyond November 26, 2001. On that date, there was a change in the point values within the rounds (for example, round one went from values of 100, 200, 300, 400, and 500 to 200, 400, 600, 800 and 1000). During the point value update, there could have been other changes made to Jeopardy impacting the daily double locations; therefore, we have excluded dates prior to the change. 

There were two main challenges in finding the positions of the daily double questions:

1. Finding the x position (the location of the categoires).
2. Finding the y position (the location of the values). 

Not all categories per episode (n = 12) were available in the dataset. To solve this issue, only episodes where all 12 categories were played were included. The assumption was that the dataset listed the categories in order by x location per episode (i.e. Category 1, Category 2, etc.). 

In addition, not every question (n = 5) within a category was availabe in the dataset. This was espeically challenging when a category contained a daily double question. Since players select their own bid for daily doubles, the value within the dataset gave little information about the location on the y axis. If there were 2 missing questions and 1 daily double within a category, the daily double could be at any of the missing value locations (Figure 1). To solve the issue, the daily double was looked at as a 'missing value', and the y position of the daily double was weighted across the three 'missing' value locations (Figure 2). 

      
```{r, echo = FALSE, fig.height= 4, fig.width = 7}
jeopardy_board %>% 
   mutate(y_pos = factor(y_pos), 
                        y_pos = factor(y_pos, levels = rev(levels(y_pos)))) %>% 
  ggplot(aes(x = x_pos, y = y_pos, fill = number_of_dd)) +
  geom_tile(color = "White", size = 0.1) +
  scale_fill_continuous(high = "#132B43", low = "white") + 
  labs(x = NULL, 
       y = NULL, 
       fill = NULL) +
  theme(legend.position = "none") + 
  geom_text(aes(label = text), color = "gray") +
  scale_x_discrete(position = "top") +
  labs(caption = paste0("Figure 1. In Category 1, the 400, 600 and 800 values",
  " were missing, and \na daily double question was asked. But it's unknown ",
  "if the daily double was \nat the 400, 600 or 800 value position.")) +
  theme(plot.caption = element_text(hjust = 0, size = rel(1.2)))
```

```{r, echo = FALSE, fig.height= 4, fig.width = 7}
weighted_jeopardy_board %>% 
   mutate(y_pos = factor(y_pos), 
                        y_pos = factor(y_pos, levels = rev(levels(y_pos)))) %>% 
  ggplot(aes(x = x_pos, y = y_pos, fill = number_of_dd)) +
  geom_tile(color = "White", size = 0.1) +
  scale_fill_continuous(high = "#132B43", low = "white") + 
  labs(x = NULL, 
       y = NULL, 
       fill = NULL) +
  theme(legend.position = "none") + 
  geom_text(aes(label = number_of_dd)) +
  scale_x_discrete(position = "top") +
  labs(caption = paste0("Figure 2. The daily double within a category was ",
                        "weighted acrossed all \nmissing values.")) +
  theme(plot.caption = element_text(hjust = 0, size = rel(1.2)))
```

# Results: 
What did you find out? Most of these slides should be figures or tables. Discuss your interpretation of your results as you present them. Ideally, you should be able to show your main results in about 3 slides, with one figure or table per slide.

The heatmaps for all years, separated by rounds, revealed interesting results. In round 1, the daily double most often occurred in category 1 and point value 400 (7.33%). Other “hot” points were category 3, value 400 (6.81%) and category 1, value 500 (6.75%). The least likely placements were across all categories in value 100 (0.35% or less) and in categories 2 (4.63% or less) and 6 (4.27% or less). Value 400 is favored across all categories (4.27% – 7.33%). In round 2, the daily double was most often located in category 1, value 400 (7.06%). The other common positions were category 5, value 400 (6.59%) and category 3, value 400 (6.41%). The likely occurrences were across value 100 (0.51% or less) and down category 2 (4.78% or less). Value 400 is elected as the position most often across categories (4.75% – 7.06%). 

Overall, the occurrence of the daily double remained extremely similar across round 1 and round 2. Our group was surprised by this outcome because we had hypothesized the rounds would differ. We were also fascinated to see the lack of variability in location. Our assumption was that the location would vary around the lower middle section of the board. 


# Conclusions: 
So what? How do your results compare with what other people have found out about your research question? Based on what you found, are there now other things you want to check out?
